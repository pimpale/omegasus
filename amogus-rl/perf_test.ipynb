{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 22:10:25.799695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-01 22:10:26.971893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from dataclasses import dataclass\n",
    "import concurrent.futures\n",
    "from collections import defaultdict\n",
    "import typing\n",
    "from torch import optim\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import env\n",
    "import network\n",
    "import player\n",
    "import visualize\n",
    "\n",
    "BOARD_XSIZE = env.BOARD_XSIZE\n",
    "BOARD_YSIZE = env.BOARD_YSIZE\n",
    "\n",
    "DIMS=(BOARD_XSIZE,BOARD_YSIZE)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "SUMMARY_DIR = './summary'\n",
    "\n",
    "# create result directory\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "cuda = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "if use_cuda:\n",
    "    device = cuda\n",
    "else:\n",
    "    device = cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (conv1): Conv2d(5, 100, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (fc1): Linear(in_features=4901, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how we saved the  models:\n",
    "#         # Save the neural net parameters to disk.\n",
    "#         if impostor_step % MODEL_SAVE_INTERVAL == 0:\n",
    "#             torch.save(impostor_actor.state_dict(), f\"{SUMMARY_DIR}/impostor_model_ep_{impostor_step}_actor.ckpt\")\n",
    "#             torch.save(impostor_critic.state_dict(), f\"{SUMMARY_DIR}/impostor_model_ep_{impostor_step}_critic.ckpt\")\n",
    "# \n",
    "#         # Save the neural net parameters to disk.\n",
    "#         if crewmate_step % MODEL_SAVE_INTERVAL == 0:\n",
    "#             torch.save(crewmate_actor.state_dict(), f\"{SUMMARY_DIR}/crewmate_model_ep_{crewmate_step}_actor.ckpt\")\n",
    "#             torch.save(crewmate_critic.state_dict(), f\"{SUMMARY_DIR}/crewmate_model_ep_{crewmate_step}_critic.ckpt\")\n",
    "        \n",
    "CREWMATE_STEP = 1000\n",
    "IMPOSTOR_STEP = 1000\n",
    "\n",
    "# load models\n",
    "impostor_actor = network.Actor().to(device)\n",
    "impostor_actor.load_state_dict(torch.load(f\"{SUMMARY_DIR}/impostor_model_ep_{IMPOSTOR_STEP}_actor.ckpt\"))\n",
    "impostor_actor.eval()\n",
    "\n",
    "impostor_critic = network.Critic().to(device)\n",
    "impostor_critic.load_state_dict(torch.load(f\"{SUMMARY_DIR}/impostor_model_ep_{IMPOSTOR_STEP}_critic.ckpt\"))\n",
    "impostor_critic.eval()\n",
    "\n",
    "crewmate_actor = network.Actor().to(device)\n",
    "crewmate_actor.load_state_dict(torch.load(f\"{SUMMARY_DIR}/crewmate_model_ep_{CREWMATE_STEP}_actor.ckpt\"))\n",
    "crewmate_actor.eval()\n",
    "\n",
    "crewmate_critic = network.Critic().to(device)\n",
    "crewmate_critic.load_state_dict(torch.load(f\"{SUMMARY_DIR}/crewmate_model_ep_{CREWMATE_STEP}_critic.ckpt\"))\n",
    "crewmate_critic.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nn player\n",
    "nn_player = player.ActorPlayer(\n",
    "    impostor_actor,\n",
    "    impostor_critic,\n",
    "    IMPOSTOR_STEP,\n",
    "    crewmate_actor,\n",
    "    crewmate_critic,\n",
    "    CREWMATE_STEP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_valid_location() -> tuple[int, int]:\n",
    "    x = np.random.randint(0, BOARD_XSIZE)\n",
    "    y = np.random.randint(0, BOARD_YSIZE)\n",
    "    return (x, y)\n",
    "\n",
    "def play_benchmark(\n",
    "    actor_engine: player.Player,\n",
    "    actor_is_impostor: bool,\n",
    "    other_engines: list[player.Player],\n",
    ") ->     list[float]:\n",
    "    # create environment\n",
    "    initial_state = env.State(\n",
    "        {},\n",
    "        np.zeros((BOARD_XSIZE, BOARD_YSIZE), dtype=np.int8),\n",
    "        np.zeros((BOARD_XSIZE, BOARD_YSIZE), dtype=np.int8),\n",
    "    )\n",
    "\n",
    "    # randomize task location\n",
    "    for _ in range(10):\n",
    "        location = random_valid_location()\n",
    "        initial_state.tasks[location] += 3\n",
    "\n",
    "    # create actor player at random location\n",
    "    actor_state = env.PlayerState(random_valid_location(), actor_is_impostor)\n",
    "    # create other players at random locations\n",
    "    other_state = [\n",
    "        env.PlayerState(random_valid_location(), False) for _ in other_engines\n",
    "    ]\n",
    "\n",
    "    # set the players in the environment\n",
    "    initial_state.players = {str(i): s for i, s in enumerate(other_state)}\n",
    "    initial_state.players[\"actor\"] = actor_state\n",
    "\n",
    "    # set the player data\n",
    "    agent_engines = {str(i): e for i, e in enumerate(other_engines)}\n",
    "    agent_engines[\"actor\"] = actor_engine\n",
    "\n",
    "    impostor = (\n",
    "        str(np.random.randint(0, len(other_engines))) if actor_is_impostor else \"actor\"\n",
    "    )\n",
    "\n",
    "    e = env.AmogusEnv(initial_state)\n",
    "\n",
    "    r_t: list[float] = []\n",
    "    # play the game\n",
    "    last_obs = e.reset()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # gather actions\n",
    "        actions = {}\n",
    "        for agent, agent_engine in agent_engines.items():\n",
    "            chosen_action = agent_engine.play(agent == impostor, last_obs[agent])\n",
    "            actions[agent] = chosen_action\n",
    "        \n",
    "        # step\n",
    "        last_obs, rewards, terminateds, truncateds, _ = e.step(actions)\n",
    "\n",
    "        # add rewards\n",
    "        r_t += [rewards[\"actor\"]]\n",
    "\n",
    "        for agent in last_obs.keys():\n",
    "            if terminateds[agent] or truncateds[agent]:\n",
    "                del agent_engines[agent]\n",
    "                # if the actor we're gathering data for is dead, then we need to stop\n",
    "                if agent == \"actor\":\n",
    "                    done = True\n",
    "    return r_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 50\n",
    "\n",
    "nn_crewmate_vs_random_impostor = []\n",
    "random_crewmate_vs_random_impostor = []\n",
    "greedy_crewmate_vs_random_impostor = []\n",
    "\n",
    "# run a couple simulations to find how well the learned policy does against a random impostor\n",
    "for _ in range(SAMPLES):\n",
    "    r_t = play_benchmark(nn_player, False, [player.RandomPlayer()]*3)\n",
    "    nn_crewmate_vs_random_impostor.append(np.sum(r_t))\n",
    "\n",
    "# run a couple simulations to find how well the random policy does against a random impostor\n",
    "for _ in range(SAMPLES):\n",
    "    r_t = play_benchmark(player.RandomPlayer(), False, [player.RandomPlayer()]*3)\n",
    "    random_crewmate_vs_random_impostor.append(np.sum(r_t))\n",
    "\n",
    "# run a couple simulations to find how well the greedy policy does against a random impostor\n",
    "for _ in range(SAMPLES):\n",
    "    r_t = play_benchmark(player.GreedyPlayer(), False, [player.RandomPlayer()]*3)\n",
    "    greedy_crewmate_vs_random_impostor.append(np.sum(r_t))\n",
    "\n",
    "\n",
    "nn_impostor_vs_random_crewmate = []\n",
    "random_impostor_vs_random_crewmate = []\n",
    "greedy_impostor_vs_random_crewmate = []\n",
    "\n",
    "# run a couple simulations to find how well the learned policy does against a random crewmate\n",
    "for _ in range(SAMPLES):\n",
    "    r_t = play_benchmark(nn_player, True, [player.RandomPlayer()]*3)\n",
    "    nn_impostor_vs_random_crewmate.append(np.sum(r_t))\n",
    "\n",
    "# run a couple simulations to find how well the random policy does against a random crewmate\n",
    "for _ in range(SAMPLES):\n",
    "    r_t = play_benchmark(player.RandomPlayer(), True, [player.RandomPlayer()]*3)\n",
    "    random_impostor_vs_random_crewmate.append(np.sum(r_t))\n",
    "\n",
    "# run a couple simulations to find how well the greedy policy does against a random crewmate\n",
    "for _ in range(SAMPLES):\n",
    "    r_t = play_benchmark(player.GreedyPlayer(), True, [player.RandomPlayer()]*3)\n",
    "    greedy_impostor_vs_random_crewmate.append(np.sum(r_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_crewmate_vs_random_impostor 2.05\n",
      "random_crewmate_vs_random_impostor 1.73\n",
      "engineered_crewmate_vs_random_impostor 0.28\n",
      "\n",
      "nn_impostor_vs_random_crewmate 1.02\n",
      "random_impostor_vs_random_crewmate 0.92\n",
      "engineered_impostor_vs_random_crewmate 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"nn_crewmate_vs_random_impostor\", np.mean(nn_crewmate_vs_random_impostor))\n",
    "print(\"random_crewmate_vs_random_impostor\", np.mean(random_crewmate_vs_random_impostor))\n",
    "print(\"engineered_crewmate_vs_random_impostor\", np.mean(greedy_crewmate_vs_random_impostor))\n",
    "print()\n",
    "print(\"nn_impostor_vs_random_crewmate\", np.mean(nn_impostor_vs_random_crewmate))\n",
    "print(\"random_impostor_vs_random_crewmate\", np.mean(random_impostor_vs_random_crewmate))\n",
    "print(\"engineered_impostor_vs_random_crewmate\", np.mean(greedy_impostor_vs_random_crewmate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_policy_vs_random_policy (crewmate): 1.1849710982658959\n",
      "nn_policy_vs_engineered_policy (crewmate): 7.32142857142857\n",
      "\n",
      "nn_policy_vs_random_policy (impostor): 1.108695652173913\n",
      "nn_policy_vs_engineered_policy (impostor): 1.59375\n"
     ]
    }
   ],
   "source": [
    "print(\"nn_policy_vs_random_policy (crewmate):\" , np.mean(nn_crewmate_vs_random_impostor)/np.mean(random_crewmate_vs_random_impostor))\n",
    "print(\"nn_policy_vs_engineered_policy (crewmate):\" , np.mean(nn_crewmate_vs_random_impostor)/np.mean(greedy_crewmate_vs_random_impostor))\n",
    "print()\n",
    "print(\"nn_policy_vs_random_policy (impostor):\" , np.mean(nn_impostor_vs_random_crewmate)/np.mean(random_impostor_vs_random_crewmate))\n",
    "print(\"nn_policy_vs_engineered_policy (impostor):\" , np.mean(nn_impostor_vs_random_crewmate)/np.mean(greedy_impostor_vs_random_crewmate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
